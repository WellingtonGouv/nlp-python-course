{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBlTNQmSrC52"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "doc = nlp('''\"Let's go to N.Y.!\"''')\n",
        "\n",
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSJWMorrtMQD",
        "outputId": "1981bb76-5359-4c8a-99a4-99efe209bac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"\n",
            "Let\n",
            "'s\n",
            "go\n",
            "to\n",
            "N.Y.\n",
            "!\n",
            "\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "doc = nlp(\"Hamilton was invited to become an aide to Continental Army general William Alexander, Lord Stirling, and another general, perhaps Nathanael Greene or Alexander McDougall.[49] He declined these invitations, believing his best chance for improving his station in life was glory on the Revolutionary War's battlefields. Hamilton eventually received an invitation he felt he could not refuse: to serve as George Washington's aide with the rank of lieutenant colonel.\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZZJARfGrSUk",
        "outputId": "6c4be038-574c-42cc-c92c-6cce7fc03255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hamilton\n",
            "was\n",
            "invited\n",
            "to\n",
            "become\n",
            "an\n",
            "aide\n",
            "to\n",
            "Continental\n",
            "Army\n",
            "general\n",
            "William\n",
            "Alexander\n",
            ",\n",
            "Lord\n",
            "Stirling\n",
            ",\n",
            "and\n",
            "another\n",
            "general\n",
            ",\n",
            "perhaps\n",
            "Nathanael\n",
            "Greene\n",
            "or\n",
            "Alexander\n",
            "McDougall.[49\n",
            "]\n",
            "He\n",
            "declined\n",
            "these\n",
            "invitations\n",
            ",\n",
            "believing\n",
            "his\n",
            "best\n",
            "chance\n",
            "for\n",
            "improving\n",
            "his\n",
            "station\n",
            "in\n",
            "life\n",
            "was\n",
            "glory\n",
            "on\n",
            "the\n",
            "Revolutionary\n",
            "War\n",
            "'s\n",
            "battlefields\n",
            ".\n",
            "Hamilton\n",
            "eventually\n",
            "received\n",
            "an\n",
            "invitation\n",
            "he\n",
            "felt\n",
            "he\n",
            "could\n",
            "not\n",
            "refuse\n",
            ":\n",
            "to\n",
            "serve\n",
            "as\n",
            "George\n",
            "Washington\n",
            "'s\n",
            "aide\n",
            "with\n",
            "the\n",
            "rank\n",
            "of\n",
            "lieutenant\n",
            "colonel\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"He gave me three $!\")\n",
        "\n",
        "token0 = doc[0]\n",
        "token0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQtF_gEnt9Lj",
        "outputId": "4eb92978-597f-49ad-fe7f-bbbae019de28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "He"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(token0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTQ_rKPxuJyR",
        "outputId": "aab99575-d0e2-48e6-dc13-f6aa0fda7e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_',\n",
              " '__bytes__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pyx_vtable__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__unicode__',\n",
              " 'ancestors',\n",
              " 'check_flag',\n",
              " 'children',\n",
              " 'cluster',\n",
              " 'conjuncts',\n",
              " 'dep',\n",
              " 'dep_',\n",
              " 'doc',\n",
              " 'ent_id',\n",
              " 'ent_id_',\n",
              " 'ent_iob',\n",
              " 'ent_iob_',\n",
              " 'ent_kb_id',\n",
              " 'ent_kb_id_',\n",
              " 'ent_type',\n",
              " 'ent_type_',\n",
              " 'get_extension',\n",
              " 'has_dep',\n",
              " 'has_extension',\n",
              " 'has_head',\n",
              " 'has_morph',\n",
              " 'has_vector',\n",
              " 'head',\n",
              " 'i',\n",
              " 'idx',\n",
              " 'iob_strings',\n",
              " 'is_alpha',\n",
              " 'is_ancestor',\n",
              " 'is_ascii',\n",
              " 'is_bracket',\n",
              " 'is_currency',\n",
              " 'is_digit',\n",
              " 'is_left_punct',\n",
              " 'is_lower',\n",
              " 'is_oov',\n",
              " 'is_punct',\n",
              " 'is_quote',\n",
              " 'is_right_punct',\n",
              " 'is_sent_end',\n",
              " 'is_sent_start',\n",
              " 'is_space',\n",
              " 'is_stop',\n",
              " 'is_title',\n",
              " 'is_upper',\n",
              " 'lang',\n",
              " 'lang_',\n",
              " 'left_edge',\n",
              " 'lefts',\n",
              " 'lemma',\n",
              " 'lemma_',\n",
              " 'lex',\n",
              " 'lex_id',\n",
              " 'like_email',\n",
              " 'like_num',\n",
              " 'like_url',\n",
              " 'lower',\n",
              " 'lower_',\n",
              " 'morph',\n",
              " 'n_lefts',\n",
              " 'n_rights',\n",
              " 'nbor',\n",
              " 'norm',\n",
              " 'norm_',\n",
              " 'orth',\n",
              " 'orth_',\n",
              " 'pos',\n",
              " 'pos_',\n",
              " 'prefix',\n",
              " 'prefix_',\n",
              " 'prob',\n",
              " 'rank',\n",
              " 'remove_extension',\n",
              " 'right_edge',\n",
              " 'rights',\n",
              " 'sent',\n",
              " 'sent_start',\n",
              " 'sentiment',\n",
              " 'set_extension',\n",
              " 'set_morph',\n",
              " 'shape',\n",
              " 'shape_',\n",
              " 'similarity',\n",
              " 'subtree',\n",
              " 'suffix',\n",
              " 'suffix_',\n",
              " 'tag',\n",
              " 'tag_',\n",
              " 'tensor',\n",
              " 'text',\n",
              " 'text_with_ws',\n",
              " 'vector',\n",
              " 'vector_norm',\n",
              " 'vocab',\n",
              " 'whitespace_']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token0.like_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSl6DXwZuQw1",
        "outputId": "530e21b4-66e1-403f-cd75-6b371ef46e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token3= doc[3]\n",
        "token3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6D3gGjpukqT",
        "outputId": "63239bdb-dff0-4c58-e89c-d34d4b4d5d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "three"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token3.like_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1ql93fuunLO",
        "outputId": "1edf12d3-7a3c-4bde-c90d-6bb32d99b8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token, \"==>\", \"index: \", token.i, \"is_alpha: \", token.is_alpha,\n",
        "        \"is_punct: \", token.is_punct,\n",
        "        \"like_num: \", token.like_num,\n",
        "        \"is_currency: \", token.is_currency,\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpX15FP1u4mc",
        "outputId": "62330c6c-a21e-498c-fdad-57136038f2de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He ==> index:  0 is_alpha:  True is_punct:  False like_num:  False is_currency:  False\n",
            "gave ==> index:  1 is_alpha:  True is_punct:  False like_num:  False is_currency:  False\n",
            "me ==> index:  2 is_alpha:  True is_punct:  False like_num:  False is_currency:  False\n",
            "three ==> index:  3 is_alpha:  True is_punct:  False like_num:  True is_currency:  False\n",
            "$ ==> index:  4 is_alpha:  False is_punct:  False like_num:  False is_currency:  True\n",
            "! ==> index:  5 is_alpha:  False is_punct:  True like_num:  False is_currency:  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"players.txt\") as f:\n",
        "  text = f.readlines()\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiETSEWmwuBE",
        "outputId": "02de5d7b-9809-4b5d-fec3-759d4cd82699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dungeons and Dragons, players information\\n',\n",
              " '==================================================\\n',\n",
              " '\\n',\n",
              " 'Name\\tbirth day   \\temail\\n',\n",
              " '-----\\t------------\\t------\\n',\n",
              " 'Gus     19 December, 2000    gus@gmail.com\\n',\n",
              " 'Leandro\\t9 February, 2001  leandro@camargo.com\\n',\n",
              " 'Caio  03 March, 2001   caio@tavares.com \\n',\n",
              " 'Samantha      1 May, 2003    sasa@root.com']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \".join(text)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "r0_y_85-w3oi",
        "outputId": "108ae6c6-75e8-48fc-81e4-095396f6a892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dungeons and Dragons, players information\\n ==================================================\\n \\n Name\\tbirth day   \\temail\\n -----\\t------------\\t------\\n Gus     19 December, 2000    gus@gmail.com\\n Leandro\\t9 February, 2001  leandro@camargo.com\\n Caio  03 March, 2001   caio@tavares.com \\n Samantha      1 May, 2003    sasa@root.com'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "\n",
        "emails = []\n",
        "\n",
        "for token in doc:\n",
        "  if token.like_email:\n",
        "    emails.append(token.text)\n",
        "emails"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnArteo0xFKU",
        "outputId": "7d99a969-ee5b-4175-9a94-b06d2183904b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gus@gmail.com', 'leandro@camargo.com', 'caio@tavares.com', 'sasa@root.com']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customizing tokenizer"
      ],
      "metadata": {
        "id": "HM3Oa-HOxfZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.symbols import ORTH\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
        "tokens = [token.text for token in doc]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gCtElNgxg29",
        "outputId": "318113db-f3da-4438-8c3e-2bad31976b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.tokenizer.add_special_case(\"gimme\", [\n",
        "    {ORTH: \"gim\"},\n",
        "    {ORTH: \"me\"},\n",
        "])\n",
        "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
        "tokens = [token.text for token in doc]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqzxl3EFxiD-",
        "outputId": "cca9edc8-d418-475e-ea2f-b666d9af195d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Tokenization or Segmentation"
      ],
      "metadata": {
        "id": "YDvDmOW3xn5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
        "for sentence in doc.sents:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "PoP66YDMxqqO",
        "outputId": "d20618ae-5fe3-4265-cc22-3f1913ec2faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1129431677.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/spacy/tokens/doc.pyx\u001b[0m in \u001b[0;36msents\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3GMP226xteM",
        "outputId": "356bb43c-8c26-4f0a-c9e1-2c801ab0b688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.add_pipe('sentencizer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev_HsVPzxv-M",
        "outputId": "be3e6bc2-ee0f-4cf0-ddd0-cda64055f86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x78489426ab90>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
        "for sentence in doc.sents:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIfKz2Rjxyie",
        "outputId": "dc671fcc-8e95-4afa-8a17-8dbda0d09102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr. Strange loves pav bhaji of mumbai.\n",
            "Hulk loves chat of delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxB39tCMxz0q",
        "outputId": "55a43f3b-4a5c-4633-a44e-73eee26eb453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sentencizer', <spacy.pipeline.sentencizer.Sentencizer at 0x78489426ab90>)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}