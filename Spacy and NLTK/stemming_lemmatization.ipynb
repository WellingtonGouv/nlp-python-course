{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming in NLTK"
      ],
      "metadata": {
        "id": "JWV-k4-62eEf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lou_BnK42XAG"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]\n",
        "\n",
        "for word in words:\n",
        "    print(word, \"|\", stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4kU3NSx2okM",
        "outputId": "fdf43ff6-c394-4fdf-addb-44f9c1e81aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating | eat\n",
            "eats | eat\n",
            "eat | eat\n",
            "ate | ate\n",
            "adjustable | adjust\n",
            "rafting | raft\n",
            "ability | abil\n",
            "meeting | meet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization in Spacy"
      ],
      "metadata": {
        "id": "P9moOdMn2q6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "0ld1YWlr2s-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VcpOmRZ4Jfk",
        "outputId": "3edd9d5d-e4de-4f1c-8ab3-f20a66ff8ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test in portuguese"
      ],
      "metadata": {
        "id": "Nl2pY0LE4jCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "#doc = nlp(\"Mando talked for 3 hours although talking isn't his thing\")\n",
        "#doc = nlp(\"eating eats eat ate adjustable rafting ability meeting better\")\n",
        "doc = nlp(\"José falou por 3 horas embora falar não seja sua praia\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token, \" | \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzerU8yU4OAf",
        "outputId": "92758162-49dc-4036-b208-577fe62bc5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "José  |  José\n",
            "falou  |  falar\n",
            "por  |  por\n",
            "3  |  3\n",
            "horas  |  hora\n",
            "embora  |  embora\n",
            "falar  |  falar\n",
            "não  |  não\n",
            "seja  |  ser\n",
            "sua  |  seu\n",
            "praia  |  praia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customizing lemmatizer"
      ],
      "metadata": {
        "id": "Xa5ew8b64puE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ar = nlp.get_pipe('attribute_ruler')\n",
        "\n",
        "ar.add([[{\"TEXT\":\"Vc\"}],[{\"TEXT\":\"Cê\"}]],{\"LEMMA\":\"Você\"})\n",
        "ar.add([[{\"TEXT\":\"tá\"}],[{\"TEXT\":\"To\"}]],{\"LEMMA\":\"estar\"})\n",
        "ar.add([[{\"TEXT\":\"cansadasso\"}]],{\"LEMMA\":\"cansado\"})\n",
        "\n",
        "doc = nlp(\"Vc quer ir pra lá? Cê tá maluco! To cansadasso.\")\n",
        "for token in doc:\n",
        "    print(token.text, \"|\", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-Z_x5HA4sDA",
        "outputId": "e001db7c-1789-45ee-dde5-08809a95bf68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vc | Você\n",
            "quer | querer\n",
            "ir | ir\n",
            "pra | pra\n",
            "lá | lá\n",
            "? | ?\n",
            "Cê | Você\n",
            "tá | estar\n",
            "maluco | maluco\n",
            "! | !\n",
            "To | estar\n",
            "cansadasso | cansado\n",
            ". | .\n"
          ]
        }
      ]
    }
  ]
}